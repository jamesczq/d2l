{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c8fa1c",
   "metadata": {},
   "source": [
    "## 2.1. Data Manipulation\n",
    "Tensors = n-dimensional arrays\n",
    "* Tensor class in Pytorch and Tensorflow\n",
    "* ndarray in Numpy and MXNet\n",
    "\n",
    "In Pytorch, tensor class \n",
    "* supports autoDiff\n",
    "* leverages GPUs (whereas Numpy only runs on CPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053f01a",
   "metadata": {},
   "source": [
    "### 2.1.1. Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cd3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdde971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, new tensors are stored in main memory and designed for CPU-based computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ce3681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed84c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total num of elements\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911c46c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tensor has shape attribute, which is a tuple of lengths along each axis/dim \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9492db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777dac58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b088bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or, we can use -1 to automatically infer one component of shape\n",
    "x.reshape(-1, 4) # No need to spell out .reshape(3, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d8df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init\n",
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7c864fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9485, -1.0332,  0.1052, -0.2226],\n",
       "        [-1.3447,  0.3089, -0.1041,  0.6267],\n",
       "        [-0.6337, -1.1708, -0.3728,  0.0455]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324bbc0e",
   "metadata": {},
   "source": [
    "### 2.1.2. Indexing, Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5456dc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad96d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, if only one index or slice is specified for a n-D tensor, it is applied along axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f028eaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f5c701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9b0c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19225dc8",
   "metadata": {},
   "source": [
    "### 2.1.3. Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0543ef8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[162754.7969, 162754.7969, 162754.7969, 162754.7969],\n",
       "        [162754.7969, 162754.7969, 162754.7969, 162754.7969],\n",
       "        [  2980.9580,   8103.0840,  22026.4648,  59874.1406]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise operations\n",
    "torch.exp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea979ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "\n",
    "x+y, x-y, x*y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13c3bce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  3.,  4.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  3.,  4.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat: along which axis to concat; along rows (axis 0) or columns (axis 1)\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "Y = torch.tensor([[2, 1, 3, 4], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c82a422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72434b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor(66.),\n",
       " tensor([12., 15., 18., 21.]),\n",
       " tensor([ 6., 22., 38.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.sum(), X.sum(axis=0), X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c88383",
   "metadata": {},
   "source": [
    "### 2.1.4 Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a19196",
   "metadata": {},
   "source": [
    "### 2.1.5. Saving Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "100066d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider Y = X + Y\n",
    "# a newly allocated memory is needed for X+Y, while the old Y is de-referenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef10c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2946437944160, 2946437937488)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = X + Y\n",
    "after = id(Y)\n",
    "before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "996d9ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2946437937488, 2946437937488, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better: update in place to reduce memory overhead\n",
    "# Also, several references may point to the same tensor; should not refer to stale parameters\n",
    "before = id(Y)\n",
    "Y += X\n",
    "after = id(Y)\n",
    "before, after, before == after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38209d4d",
   "metadata": {},
   "source": [
    "### 2.1.6 Conversion to Other Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2261143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bccb28bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.2000]), 1.2000000476837158)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get a scalar (1-d array in pytorch)\n",
    "a = torch.tensor([1.2])\n",
    "a, a.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f279c2",
   "metadata": {},
   "source": [
    "## 2.2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5854cf",
   "metadata": {},
   "source": [
    "### 2.2.1. Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13294232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcf59f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78bc4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c237530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>RoofType</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Slate</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms RoofType   Price\n",
       "0       NaN      NaN  127500\n",
       "1       2.0      NaN  106000\n",
       "2       4.0    Slate  178100\n",
       "3       NaN      NaN  140000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9028b657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>RoofType_Slate</th>\n",
       "      <th>RoofType_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms  RoofType_Slate  RoofType_nan\n",
       "0       NaN               0             1\n",
       "1       2.0               0             1\n",
       "2       4.0               1             0\n",
       "3       NaN               0             1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how missing values are treated in the following two cells\n",
    "inputs, targets = data.iloc[:,:2], data.iloc[:,2]\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9913790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>RoofType_Slate</th>\n",
       "      <th>RoofType_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms  RoofType_Slate  RoofType_nan\n",
       "0       3.0               0             1\n",
       "1       2.0               0             1\n",
       "2       4.0               1             0\n",
       "3       3.0               0             1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c00408",
   "metadata": {},
   "source": [
    "### 2.2.3. Conversion to the Tensor Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dd58312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = torch.tensor(inputs.values), torch.tensor(targets.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33b91c",
   "metadata": {},
   "source": [
    "## 2.3. Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a75ca0",
   "metadata": {},
   "source": [
    "### 2.3.1. Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37136868",
   "metadata": {},
   "source": [
    "### 2.3.2. Vectors\n",
    "1-d array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700356cb",
   "metadata": {},
   "source": [
    "### 2.3.3. Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38736f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 2, 4],\n",
       "         [1, 3, 5]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3,-1)\n",
    "A, A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c69202d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [2, 0, 4],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [2, 0, 4],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[True, True, True],\n",
       "         [True, True, True],\n",
       "         [True, True, True]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A, A.T, A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a5a7c",
   "metadata": {},
   "source": [
    "### 2.3.4. Tensors\n",
    "* An image is a 3-d tensor: axes = height, width, channel\n",
    "* A video is a 4-d tensor: axes = time, height, width, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f533e4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[16, 17],\n",
       "         [18, 19],\n",
       "         [20, 21],\n",
       "         [22, 23]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(3, 4, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efca66",
   "metadata": {},
   "source": [
    "### 2.3.5. Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f541841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  1.,  4.],\n",
       "         [ 9., 16., 25.]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise product of two matrices is called the Hadamard product\n",
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()\n",
    "A, B, A*B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605f181",
   "metadata": {},
   "source": [
    "### 2.3.6. Reduction\n",
    "By default, .sum() reduces a tensor along all of its axes.\n",
    "\n",
    "To sum over along the row, specify axis=0; to over column, axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61a414e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor(15.))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a4f49b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 5., 7.]), torch.Size([3]), tensor([ 3., 12.]), torch.Size([2]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sums of columns, sums of rows\n",
    "A.sum(axis=0), A.sum(axis=0).shape, A.sum(axis=1), A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca265207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor(2.5000),\n",
       " tensor([1.5000, 2.5000, 3.5000]),\n",
       " tensor([1., 4.]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likewise for .mean()\n",
    "A, A.mean(), A.mean(axis=0), A.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f1a30",
   "metadata": {},
   "source": [
    "### 2.3.7. Non-Reduction Sum\n",
    "Sometimes, it can be useful to keep the number of axes unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe2c3fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "A, A.shape, sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36d90329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since sum_A keeps its two axes, we can use it to \"normalize\" each row of A (so each row of A add up to 1)\n",
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd0a0394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  3.],\n",
       "        [ 3.,  7., 12.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By design, .cumsum() keeps dim\n",
    "A.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e034aed",
   "metadata": {},
   "source": [
    "### 2.3.8. Dot Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82d54ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "946ce31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones_like(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b3b23c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.]), tensor([1., 1., 1.]), tensor(6.), tensor(6.))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, torch.dot(x, y), torch.sum(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8986c0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat = x / (torch.dot(x, x))**0.5\n",
    "(torch.dot(xhat, xhat))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f36f3",
   "metadata": {},
   "source": [
    "### 2.3.9. Matrix-Vector Products\n",
    "(Ax)[i] = torch.dot(A[i,:], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c563658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e6a0aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), tensor([ 8., 26.]), tensor([ 8., 26.]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x), A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d065bf",
   "metadata": {},
   "source": [
    "### 2.3.10. Matrix-Matrix Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "024cb560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3, 4)\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14632934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A, B), A@B # Should not be confused with Hadamard Product A*B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d0630",
   "metadata": {},
   "source": [
    "### 2.3.11. Norms\n",
    "A notion about the size, magnitude, not its dimensionality\n",
    "\n",
    "A norm is a function from a vector space to a scalar such that\n",
    "* norm(X) > 0 for all X != 0\n",
    "* norm(aX) = abs(a)*norm(X)\n",
    "* norm(X + Y) <= norm(X) + norm(Y)\n",
    "\n",
    "Why this concept is useful?\n",
    "* In deep learning, we are solving optimization problems: maximize the probability assigned to observed data, maximize the revenue associated with a recommender, minimize the distance between predictions and ground-truth observations, minimize distance(same person's photos) while maximize distance(diff persons' photos)\n",
    "* These distances (often the objectives of DL algos) are often expressed as norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56ca49ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 4.]]), tensor(7.), tensor(7.))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 norm\n",
    "x = torch.tensor([[3, 4]], dtype=torch.float32)\n",
    "x, torch.norm(x, p=1), torch.sum(torch.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fee1ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 4.]]), tensor(5.), tensor(5.))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 norm\n",
    "x, torch.norm(x, p=2), (torch.sum(torch.abs(x**2)))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a8cc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_norm(vec, p):\n",
    "    norm = torch.sum(torch.abs(x**p))\n",
    "    norm = norm**(1/p)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3013a253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(5.))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_norm(x, 1), lp_norm(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a05d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
